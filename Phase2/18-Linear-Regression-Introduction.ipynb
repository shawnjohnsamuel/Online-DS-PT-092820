{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AKA - Welcome to statistical modeling! Could also say - welcome to **Supervised Machine Learning**.\n",
    "\n",
    "What do I mean by 'Supervised' ?\n",
    "\n",
    "![Types of machine learning, broken down](images/machinelearning_supervisedunsupervised.png)\n",
    "\n",
    "[Image Source](https://fr.mathworks.com/help/stats/machine-learning-in-matlab.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first model:\n",
    "\n",
    "$$ y = m \\cdot x + b $$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $x$: input column (just one for now)\n",
    "- $y$: output column (column we're trying to predict)\n",
    "\n",
    "Solving for the coefficients $m$ and $b$ - our slope and y-intercept - based on the line that 'best' represents the relationship between $x$ and $y$, _assuming_ that relationship is a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's say that we assume that spending money on TV advertising has an impact on our sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data\n",
    "df = pd.read_csv('data/Advertising.csv', index_col=0)[['TV', 'Sales']]\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use a scatter plot to explore relationship between 2 variables\n",
    "plt.scatter(df['TV']*1000, df['Sales']*1000) # table shows thousand dollar units\n",
    "plt.ylabel('Sales in Dollars')\n",
    "plt.xlabel('TV Advertising in Dollars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn even has a 'best fit line' plot\n",
    "sns.lmplot(x='TV', y='Sales', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what are those parameters found by seaborn above, and how can we solve for them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with `statsmodels`\n",
    "\n",
    "`statsmodels` is more robust than `sklearn` for linear models, but as a library has a lot less functionality for modeling techniques.\n",
    "\n",
    "[Check the documentation](http://www.statsmodels.org/devel/generated/statsmodels.regression.linear_model.OLS.html#statsmodels.regression.linear_model.OLS)\n",
    "\n",
    "Now let's use statsmodel to fit a linear model to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use capital `X` to capture inputs and lowercase `y` to capture the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = None\n",
    "print(X.shape)\n",
    "\n",
    "y = None\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's model!\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit() # actually fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params # seeing our coefficients - just one, we'll discuss in a sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.predict([150, 2, 300]) # predicting for some random possible X values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['TV'], df['Sales'])\n",
    "\n",
    "x_pred_range = np.linspace(0, 300, 300)\n",
    "plt.plot(x_pred_range, results.predict(x_pred_range))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay... just one parameter though, a slope - why no intercept? Because statsmodels is weird and assumes you add a constant manually if you want one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_with_const = sm.add_constant(X) # easiest way to add the constant\n",
    "pd.DataFrame(X_with_const, columns=['ones', 'TV']).head() # showing the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's redo that modeling process\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['TV'], df['Sales'])\n",
    "\n",
    "x_pred_range = np.linspace(0, 300, 300)\n",
    "plt.plot(x_pred_range, results.predict(sm.add_constant(x_pred_range)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat.\n",
    "\n",
    "So, uh... how'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding $R^{2}$ - How do we know what's 'best' ?\n",
    "\n",
    "The easiest way to think about an R2 score, also known as the Coefficient of Determination, is that it compares how much more variance in `y` you explain with your model compared to predicting that `y` is always the mean value.\n",
    "\n",
    "Let's explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['TV'], df['Sales'])\n",
    "xmin, xmax = plt.xlim()\n",
    "\n",
    "plt.hlines(y=df['Sales'].mean(),\n",
    "           xmin=xmin, xmax=xmax,\n",
    "           label=f'Mean Sales Across Cities is {df[\"Sales\"].mean():.2f}')\n",
    "\n",
    "plt.title('Predicting Sales from Mean')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as we can see this is not explaining what is going on in the data very well. We know this amount of errors as Total Sum of Squares.\n",
    "\n",
    "\n",
    "$$ \\text{Total Sum of Squares} = \\sum\\limits_{i=1}^{200} (y_{i} - \\bar{y})^{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Total Sum of Squares\n",
    "y_bar = None\n",
    "\n",
    "TSS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But after we fit a linear regression line we have a better fit than just \"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this bypasses needing to add the constant separately\n",
    "y_pred = results.predict(sm.add_constant(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "# this plots the actual data\n",
    "plt.scatter(X, y)\n",
    "\n",
    "# this plots the 'best' line\n",
    "plt.plot(X, y_pred, label=\"Line of Best Fit\", color='r')\n",
    "# and this plots the 'average' line\n",
    "plt.hlines(y_bar, X.min(), X.max(), label=\"Average Y\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this line is also not 'perfect' from prediction point of view. Let's see how much is the total amount of error this time.\n",
    "\n",
    "A **residual** is the difference between the actual value and the predicted value for a point we tried to predict where we knew the actual correct answer.\n",
    "\n",
    "<img src=\"images/errors.png\" cap=\"Transformed dataset\"  width='500'/>\n",
    "\n",
    "$$ \\text{Squared Sum of Residuals} = \\sum\\limits_{i=1}^{n} (y_i - \\text{y_pred}_{i})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = None\n",
    "\n",
    "# now sum the squared residuals\n",
    "RSS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total Squared Sum is {TSS:.3f}')\n",
    "print(f'Residual Squared Sum is {RSS:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^{2}$ measurement is just their ratio:\n",
    "\n",
    " $$ R^{2} = \\frac{TSS - RSS}{TSS} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_squared = None\n",
    "\n",
    "R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can grab this straight from our results\n",
    "results.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is also given in the summary of results\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `statsmodels`: $R^2$ and Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Recap:\n",
    "# we first construct our model\n",
    "\n",
    "\n",
    "# by fitting we learn 'best' coefficients for intercept and slope\n",
    "\n",
    "\n",
    "# with the summary method we can see all the relevant statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also check the parameters of our results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose our company wants to invest $230K in TV ads in a city, how much sales would you expect on average for this city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, with our model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this prediction is nothing but \n",
    "\n",
    "$$ \\text{Sales} = 0.0475 \\times \\text{TV Advertising} + 7.0326 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = None\n",
    "\n",
    "slope = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, instantiate the model \n",
    "# note that we don't pass in our data yet - different from statsmodels\n",
    "lr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, fit the model\n",
    "lr.fit(df[['TV']], y)\n",
    "\n",
    "# same as\n",
    "# lr.fit(X.reshape(-1, 1), y) <- need .reshape because it's surprised X is one-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best slope value slope\n",
    "m = lr.coef_\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best intercept value\n",
    "b = lr.intercept_\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_manual = m*X + b\n",
    "y_pred_model = lr.predict(X.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_manual == y_pred_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_pred_model, color='orange')\n",
    "\n",
    "plt.xlabel('TV Advertising (in thousands of dollars)')\n",
    "plt.ylabel('Sales (in thousands of dollars)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the R2 score from sklearn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first actual values, then predicted values\n",
    "r2_score(y, y_pred_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond the $R^2$ Score\n",
    "\n",
    "There are other metrics! \n",
    "\n",
    "#### Mean Absolute Error (MAE)\n",
    "\n",
    "$$\\text{MAE}(y, y_\\text{pred}) = \\frac{1}{n} \\sum_{i=0}^{n} \\left| y_i - y_\\text{pred}i \\right|$$\n",
    "\n",
    "- Measures the average magnitude of errors regardless of direction, by calculating the total absolute value of errors and dividing by the number of samples (number of predictions made)\n",
    "- This error term is in the same units as the target!\n",
    "\n",
    "#### Mean Squared Error (MSE)\n",
    "\n",
    "$$\\text{MSE}(y, y_\\text{pred}) = \\frac{1}{n} \\sum_{i=0}^{n} (y_i - y_\\text{pred}i)^2$$\n",
    "\n",
    "- Measures the average squared error, by calculating the sum of squared errors for all predictions then dividing by the number of samples (number of predictions)\n",
    "- In other words - this is the Total Sum of Squares (TSS) divided by the number of predictions!\n",
    "- This error term is **NOT** in the same units as the target!\n",
    "\n",
    "#### Root Mean Squared Error (RMSE)\n",
    "\n",
    "$$\\text{RMSE}(y, y_\\text{pred}) = \\sqrt{\\frac{1}{n} \\sum_{i=0}^{n} (y_i - y_\\text{pred}i)^2}$$\n",
    "\n",
    "- Measures the square root of the average squared error, by calculating the sum of squared errors for all predictions then dividing by the number of samples (number of predictions), then taking the square root of all that\n",
    "- This error term is in the same units as the target!\n",
    "\n",
    "Note - before, we were _maximizing_ R2 (best fit = largest R2 score). But we'd want to minimize these other error metrics.\n",
    "\n",
    "Documentation: \n",
    "- [Regression Metrics in sklearn](https://scikit-learn.org/stable/modules/classes.html#regression-metrics)\n",
    "- [User Guide for Regression Metrics in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics:\")\n",
    "# R2\n",
    "print(f\"R2: {r2_score(y, y_pred_model):.3f}\")\n",
    "# MAE\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y, y_pred_model):.3f}\")\n",
    "# MSE\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y, y_pred_model):.3f}\")\n",
    "# RMSE - just MSE but set squared=False\n",
    "print(f\"Root Mean Squared Error: {mean_squared_error(y, y_pred_model, squared=False):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I said that MAE and RMSE are both in the same units as our target, but you'll see that they are different here. What's the difference?\n",
    "\n",
    "> \"Taking the square root of the average squared errors has some interesting implications for RMSE. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable.\"\n",
    "\n",
    "-- Source: [\"MAE and RMSE — Which Metric is Better?\"](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we interpret these?\n",
    "\n",
    "- R2: \"Our model accounts for 61.2% of the variance in our target\"\n",
    "- MAE/RMSE: \"Our model's predictions are, on average, about __ dollars away from our actual target values\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important note to keep in mind from now on:\n",
    "\n",
    "![\"all models are wrong but some are useful\" quote picture](images/allmodelsarewrong.jpg)\n",
    "\n",
    "[Image Source](https://twitter.com/cwodtke/status/1244433603666178049)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
