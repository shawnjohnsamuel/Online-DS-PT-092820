{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' Theorem\n",
    "\n",
    "## $$P(A\\mid B)=\\frac {P(B\\mid A) \\cdot P(A)}{P(B)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "- $P(A)$ : \n",
    "    - The probability of an event irrespective of the outcomes of other random variables is called the ***marginal probability***.\n",
    "    - In reference to Bayes' Theorem, this is known as the ***prior probability***.\n",
    "\n",
    "- $P(A|B)$ :\n",
    "    - The probability of one (or more) event(s) given the occurence of another event is called the ***conditional probability***.\n",
    "    - In reference to Bayes' Theorem, this is known as the ***posterior probability***.\n",
    "\n",
    "- $P(B|A)$ : ***Likelihood***.\n",
    "\n",
    "- $P(B)$ : ***Evidence***.\n",
    "\n",
    "This allows us to restate the theorem as\n",
    "\n",
    "$$\n",
    "\\textrm{Posterior} = \\frac{\\textrm{Likelihood}\\cdot\\textrm{Prior}}{\\textrm{Evidence}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerator, $P(B\\mid A) \\cdot P(A)$, is a **joint probability**.\n",
    "\n",
    "\n",
    "- A joint probability is the probability of two (or more) simultaneous events\n",
    "    - $P(A,B)$ or $P(A \\cap B) = P(A|B)\\cdot P(B)$\n",
    "    - So, in the theorem: $P(B,A)$ or $P(B \\cap A) = P(B|A)\\cdot P(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "_____\n",
    "\n",
    "- What is the probability that there is rain given that there are clouds?\n",
    "\n",
    "\n",
    "\n",
    "_____\n",
    "\n",
    "- What is the probability that there is fire given that there is smoke?\n",
    "\n",
    "\n",
    "_____\n",
    "\n",
    "- What is the probability that you have cancer given that you tested positive?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "Yes, you do just need to remember which piece is which...\n",
    "\n",
    "<center><img src='https://imgs.xkcd.com/comics/modified_bayes_theorem_2x.png' width=500></center>\n",
    "\n",
    "[Image Source: XKCD](https://xkcd.com/2059/)\n",
    "\n",
    "(for the record, $P(C)$ in this example is always very low)\n",
    "\n",
    "_____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Theorem with...  Legos?\n",
    "\n",
    "Will Kurt, who writes the [Count Bayesie blog](https://www.countbayesie.com/) and is the author of [_Bayesian Statistics the Fun Way_](https://nostarch.com/learnbayes), uses legos to derive Bayes' Theorem. Let's take a look: https://www.countbayesie.com/blog/2015/2/18/bayes-theorem-with-lego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How About Bayes' Theorem with Waterfalls?\n",
    "\n",
    "[This great resource by Arbital](https://arbital.com/p/bayes_rule/?l=1zq) will let you go into all kinds of detail about the intuition behind Bayes' Theorem.\n",
    "\n",
    "We can skip straight to their one-pager: https://arbital.com/p/bayes_rule/?l=693"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: 1984 Congressional Voting Data\n",
    "\n",
    "Let's do an example. Here's the real theorem again for reference:\n",
    "\n",
    "## $$P(A\\mid B)=\\frac {P(B\\mid A) \\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Data source: [Congressional Quarterly Almanac, 98th Congress, 2nd session 1984](https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records)\n",
    "\n",
    "A congressman voted no on providing aid to El Salvador. Given that 61% of the congress were Democrats, 74.9% of whom voted 'No' for providing aid to El Salvador, and only 4.8% of Republicans voted 'No' to the proposal, what is the conditional probability that this individual is a Democrat?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which probability are we trying to find?\n",
    "\n",
    "    - \n",
    "    \n",
    "2. Based on that, what other pieces do we need?\n",
    "\n",
    "    - \n",
    "    \n",
    "3. Result?\n",
    "\n",
    "    - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have this data, we can do this even more exactly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, then grab and explore the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab just the data for the el-salvador-aid vote\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find these pieces exactly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: MLE? MAP?\n",
    "\n",
    "If we have time, we can also chat about the two other seemingly-random pieces in this curriculum topic: Maximum Likelihood Estimation (MLE) and the Maximum A Posteriori Estimation (MAP). These are how we estimate parameters given some data.\n",
    "\n",
    "For this, let's go back to Will Kurt: \n",
    "\n",
    "> \"When we start learning probability we often are told the probability of an event and from there try to estimate the likelihood of various outcomes. In reality the inverse is much more common: we have data about the outcomes but don't really know what the true probability of the event is. Trying to figure out this missing parameter is referred to as Parameter Estimation.\"\n",
    "\n",
    "-- https://www.countbayesie.com/blog/2015/4/4/parameter-estimation-the-pdf-cdf-and-quantile-function\n",
    "\n",
    "Also: https://www.countbayesie.com/blog/2015/4/4/parameter-estimation-adding-bayesian-priors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
