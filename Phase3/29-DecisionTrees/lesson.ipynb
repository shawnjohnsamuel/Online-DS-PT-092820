{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:13.903970Z",
     "start_time": "2021-03-01T22:26:13.560755Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "**Decision Tree** is a popular supervised learning algorithm known for its high interpretability. Decision Tree models are considered to have low computational cost in comparison to many other algorithms, but Decision Trees are [non parametric](https://sebastianraschka.com/faq/docs/parametric_vs_nonparametric.html) which means their [computational cost](https://www.thekerneltrip.com/machine/learning/computational-complexity-learning-algorithms/) grows exponentially as the size of the dataset increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros & Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Easy to explain and visualize\n",
    "- Irrelevant features will not be used by the model (built in feature selection)\n",
    "    - Decision Trees can be used to identify the predictive power of features with non-linear relationships! More [here](https://towardsdatascience.com/rip-correlation-introducing-the-predictive-power-score-3d90808b9598)\n",
    "- Preprocessing needs are minimal\n",
    "    - Scaling doesn't have a high impact on results.\n",
    "    - Multicollinearity doesn't impact results.\n",
    "    - Outliers have a low impact on results.\n",
    "- Very fast prediction speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T17:51:28.078778Z",
     "start_time": "2021-03-01T17:51:28.075539Z"
    }
   },
   "source": [
    "- High variability (Easily overfits to data)\n",
    "- Training time increases exponentially as sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pro + Con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Trees have a lot of tuning options (hyper parameters)\n",
    "    - Pro\n",
    "        - Models can be highly customizable and optimized!\n",
    "    - Con\n",
    "        - There is a learning curve to using these tuning options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree filters the data according to a series of `if` and `else` statements. \n",
    "\n",
    "<img src=\"simple_example.png\" style=\"height:300px;\">\n",
    "\n",
    "Above is an extremely simple example of a decision tree, let's look at an example that is a little more complicated. \n",
    "\n",
    "**Say we have an unorganized drawer of pens and pencils. The pens and pencils are made with the following materials:**\n",
    "\n",
    "<img src=\"writing_utensils.png\" style=\"width:600px;\">\n",
    "\n",
    "In the cell below, we import data for this drawer:\n",
    "> For the type column, 0 = pencil and 1 = pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:13.926153Z",
     "start_time": "2021-03-01T22:26:13.909429Z"
    }
   },
   "outputs": [],
   "source": [
    "utensils = pd.read_csv('writing_utensils.csv')\n",
    "utensils.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we are doing a classification problem, one of the first things we should check is the distribution of the classification column. We can do this by running `.value_counts()` on this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:13.972149Z",
     "start_time": "2021-03-01T22:26:13.938390Z"
    }
   },
   "outputs": [],
   "source": [
    "utensils.type.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very close to evenly split. That's a good thing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we group by `type` we can look at the joint probabilities for pens and pencils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:13.989778Z",
     "start_time": "2021-03-01T22:26:13.980416Z"
    }
   },
   "outputs": [],
   "source": [
    "utensils.groupby('type').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:14.005714Z",
     "start_time": "2021-03-01T22:26:14.002522Z"
    }
   },
   "outputs": [],
   "source": [
    "utensils.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the table above, what observations can we make about the pens and pencils in our drawer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T17:05:56.425693Z",
     "start_time": "2021-03-01T17:05:56.422563Z"
    }
   },
   "source": [
    "1.   \n",
    "2.   \n",
    "3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:14.011780Z",
     "start_time": "2021-03-01T22:26:14.007120Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vRjpSr7iFUUJLV8RrrLtBF3czpuhV4iKnAylzbhDLlrvYirUO6hmNxyEerJjC8uTyIbA8WpDN1ZvnHR/embed?start=false&loop=false&delayms=3000\" frameborder=\"0\" width=\"960\" height=\"400\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's code out our decision tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:14.020565Z",
     "start_time": "2021-03-01T22:26:14.018452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What observations did we classify incorrectly?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:14.600623Z",
     "start_time": "2021-03-01T22:26:14.598473Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How can we do this with sklearn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:30:59.701219Z",
     "start_time": "2021-03-01T22:30:59.693810Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = utensils.drop('type', axis=1)\n",
    "y = utensils.type\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X,y)\n",
    "dt.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T17:57:02.211374Z",
     "start_time": "2021-03-01T17:57:02.206732Z"
    }
   },
   "source": [
    "**Plotting an sklearn decision tree!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:15.010566Z",
     "start_time": "2021-03-01T22:26:14.681772Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(dt, feature_names=X.columns, filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does a decision tree make decisions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two available cost functions that a decision tree can use:\n",
    "1. The Gini Index\n",
    "2. Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Gini Index = 1 â€“ \\sum_{j}p_{j}^{2}$\n",
    "\n",
    "j = A class label\n",
    "\n",
    "p = The proportion of observations in the split for the j class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn this into a function!\n",
    "\n",
    "In the cell below we create a `gini_index` function that:\n",
    "1. receives a pandas series\n",
    "2. calculates the proportions for each class in the series\n",
    "3. Calculates and returns the gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:15.222122Z",
     "start_time": "2021-03-01T22:26:15.220365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's use our gini index function to calculate the gini score for each split of our decision tree!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we calculate the gini score for whether or not the utensil is made of wood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:31:02.481569Z",
     "start_time": "2021-03-01T22:31:02.472447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect the index for observations \n",
    "# that are made of wood\n",
    "wood_index = X[utensils.wood > .5].index\n",
    "\n",
    "# Collect the index for observations \n",
    "# that are not made of wood\n",
    "not_wood_index = X[utensils.wood <= .5].index\n",
    "\n",
    "# Collect the labels for both groups\n",
    "wood_labels = y.loc[wood_index]\n",
    "not_wood_labels = y.loc[not_wood_index]\n",
    "\n",
    "# Calculate the gini score for each!\n",
    "wood_gini = gini_index(wood_labels)\n",
    "not_wood_gini = gini_index(not_wood_labels)\n",
    "print(f'Wood Gini: {wood_gini}')\n",
    "print(f'Not Wood Gini: {not_wood_gini}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take the observations that are not made of wood, and split them according to whether or not they have a cap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:15.257231Z",
     "start_time": "2021-03-01T22:26:15.247660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect the index for observations \n",
    "# that are not made of wood and have a cap\n",
    "mask = (X.loc[not_wood_index].has_cap > .5)\n",
    "no_wood_with_cap_index = (X.loc[not_wood_index][mask]).index\n",
    "\n",
    "# Collect the index for observations \n",
    "# that are not made of wood and have do not have a cap\n",
    "mask = (X.loc[not_wood_index].has_cap <= .5)\n",
    "no_wood_no_cap_index = (X.loc[not_wood_index][mask]).index\n",
    "\n",
    "# Collect class labels for both groups\n",
    "no_wood_with_cap_labels = y.loc[no_wood_with_cap_index]\n",
    "no_wood_no_cap_labels = y.loc[no_wood_no_cap_index]\n",
    "\n",
    "# Calculate the gini score for each!\n",
    "no_wood_with_cap_gini = gini_index(no_wood_with_cap_labels)\n",
    "no_wood_no_cap_gini = gini_index(no_wood_no_cap_labels)\n",
    "\n",
    "\n",
    "print(f'No Wood With Cap Gini: {no_wood_with_cap_gini}')\n",
    "print(f'No Wood No Cap Gini: {no_wood_no_cap_gini}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we take the observations that are not made of wood and do not have have a cap, and we split them according to whether or not they are made of metal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:15.287754Z",
     "start_time": "2021-03-01T22:26:15.270542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect the index for observations \n",
    "# that are not made of wood and have a cap\n",
    "mask = (X.loc[no_wood_no_cap_index].metal > .5)\n",
    "no_wood_no_cap_metal_index = (X.loc[no_wood_no_cap_index][mask]).index\n",
    "\n",
    "# Collect the index for observations \n",
    "# that are not made of wood and have do not have a cap\n",
    "mask = (X.loc[no_wood_no_cap_index].metal <= .5)\n",
    "no_wood_no_cap_no_metal_index = (X.loc[no_wood_no_cap_index][mask]).index\n",
    "\n",
    "# Collect class labels for both groups\n",
    "no_wood_no_cap_metal_labels = y.loc[no_wood_no_cap_metal_index]\n",
    "no_wood_no_cap_no_metal_labels = y.loc[no_wood_no_cap_no_metal_index]\n",
    "\n",
    "# Calculate the gini score for each!\n",
    "no_wood_no_cap_metal_gini = gini_index(no_wood_no_cap_metal_labels)\n",
    "no_wood_no_cap_no_metal_gini = gini_index(no_wood_no_cap_no_metal_labels)\n",
    "\n",
    "\n",
    "print(f'No Wood No Cap Metal Gini: {no_wood_no_cap_metal_gini}')\n",
    "print(f'No Wood No Cap No Metal Gini: {no_wood_no_cap_no_metal_gini}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does Decision Tree decide on splits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every split, the decision tree:\n",
    "1. Loops over every column\n",
    "2. Splits the data according to every unique value in the column\n",
    "3. Calculates the gini score for every split\n",
    "4. Returns the split that resulted in the best gini score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:15.347576Z",
     "start_time": "2021-03-01T22:26:15.307254Z"
    }
   },
   "outputs": [],
   "source": [
    "# The maximum score for gini is .5\n",
    "# Any score that is less than 1 is an improvement\n",
    "# So we will set the best score to .5 and check \n",
    "# if our calculates scores of better\n",
    "best_score = .5\n",
    "# Variable to contain information about \n",
    "# The best split of the data\n",
    "best_split = None\n",
    "\n",
    "# Loop over every column\n",
    "for column in X.columns:\n",
    "    # Find all the unique values in the column\n",
    "    unique = utensils[column].unique()\n",
    "    # Loop over every unique value\n",
    "    for val in unique:\n",
    "        # split the data according to the unique value\n",
    "        split_1 = utensils[utensils[column] <= val]\n",
    "        split_2 = utensils[utensils[column] >= val]\n",
    "        # Calculate the gini score for each split\n",
    "        split_1_score = gini_index(split_1.type)\n",
    "        split_2_score = gini_index(split_2.type)\n",
    "        # Add the gini scores together\n",
    "        score = split_1_score + split_2_score\n",
    "        # If the score if less than the best score\n",
    "        # set the best score to the score we have \n",
    "        # calculated and set the best split\n",
    "        # to the name of the column and the value\n",
    "        # we split on\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_split = (column, val)\n",
    "            \n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Split: {best_split}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T21:20:36.798388Z",
     "start_time": "2021-03-01T21:20:36.795963Z"
    }
   },
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Entropy = â€“ \\sum_{j}p_{j} \\cdot log_{2} \\cdot p_{j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:15.389511Z",
     "start_time": "2021-03-01T22:26:15.386527Z"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(series):\n",
    "    proportions = series.value_counts(normalize=True)\n",
    "    proportions = proportions * np.log2(proportions)\n",
    "    proportions = proportions.sum()\n",
    "    return -proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the code above, and replace `gini_index` with our `entropy` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:15.434438Z",
     "start_time": "2021-03-01T22:26:15.395218Z"
    }
   },
   "outputs": [],
   "source": [
    "# The maximum score for entropy is 1\n",
    "# Any score that is less than 1 is an improvement\n",
    "# So we will set the best score to 1 and check \n",
    "# if our calculates scores of better\n",
    "best_score = 1\n",
    "# Variable to contain information about \n",
    "# The best split of the data\n",
    "best_split = None\n",
    "\n",
    "# Loop over every column\n",
    "for column in X.columns:\n",
    "    # Find all the unique values in the column\n",
    "    unique = utensils[column].unique()\n",
    "    # Loop over every unique value\n",
    "    for val in unique:\n",
    "        # split the data according to the unique value\n",
    "        split_1 = utensils[utensils[column] <= val]\n",
    "        split_2 = utensils[utensils[column] >= val]\n",
    "        # Calculate the entropy for each split\n",
    "        split_1_score = entropy(split_1.type)\n",
    "        split_2_score = entropy(split_2.type)\n",
    "        # Add the entropy scores together\n",
    "        score = split_1_score + split_2_score\n",
    "        # If the score if less than the best score\n",
    "        # set the best score to the score we have \n",
    "        # calculated and set the best split\n",
    "        # to the name of the column and the value\n",
    "        # we split on\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_split = (column, val)\n",
    "            \n",
    "print(f'Best Score: {best_score}')\n",
    "print(f'Best Split: {best_split}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:15.697312Z",
     "start_time": "2021-03-01T22:26:15.475671Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy')\n",
    "dt.fit(X,y)\n",
    "plot_tree(dt, feature_names=X.columns, filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between gini and entropy? \n",
    "\n",
    "Due to time, this question is slightly out of scope for this lesson. For a good explanation, see [this article](https://quantdare.com/decision-trees-gini-vs-entropy/)\n",
    "\n",
    "The TL;DR is that entropy is more computationally expensive (the model takes longer to fit to data) than gini, but entropy tends to perform slightly better in terms of accuracy than gini. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:16.236648Z",
     "start_time": "2021-03-01T22:26:15.905018Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/fa71405126017e6a37bea592440b4bee94bf7b9e/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:16.250769Z",
     "start_time": "2021-03-01T22:26:16.237957Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:16.254179Z",
     "start_time": "2021-03-01T22:26:16.252227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import decision tree classifier\n",
    "\n",
    "# Other imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:16.261542Z",
     "start_time": "2021-03-01T22:26:16.259450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select the features I'd like to use\n",
    "\n",
    "# Drop null values for according to selected features\n",
    "\n",
    "# Isolate the target\n",
    "\n",
    "# Isolate the predictors\n",
    "\n",
    "# Instantiate a label encoder\n",
    "\n",
    "# Fit the label encoder to the categorical data\n",
    "\n",
    "# Transform the categorical data\n",
    "\n",
    "\n",
    "# Create a train test split\n",
    "\n",
    "\n",
    "# Fit the decision tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's score the decision tree model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:16.290839Z",
     "start_time": "2021-03-01T22:26:16.284986Z"
    }
   },
   "outputs": [],
   "source": [
    "dt.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's score the decision tree model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:16.297611Z",
     "start_time": "2021-03-01T22:26:16.292499Z"
    }
   },
   "outputs": [],
   "source": [
    "dt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:21.512235Z",
     "start_time": "2021-03-01T22:26:16.299169Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tree(dt, feature_names=X.columns, filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:21.516814Z",
     "start_time": "2021-03-01T22:26:21.514044Z"
    }
   },
   "outputs": [],
   "source": [
    "second_model = DecisionTreeClassifier(max_depth=5, min_samples_split = 10, max_leaf_nodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:21.524981Z",
     "start_time": "2021-03-01T22:26:21.518548Z"
    }
   },
   "outputs": [],
   "source": [
    "second_model.fit(X_train, y_train)\n",
    "second_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:21.531826Z",
     "start_time": "2021-03-01T22:26:21.526354Z"
    }
   },
   "outputs": [],
   "source": [
    "second_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:22.371830Z",
     "start_time": "2021-03-01T22:26:21.533389Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tree(second_model, feature_names=X.columns, filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:22.375452Z",
     "start_time": "2021-03-01T22:26:22.372953Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:22.598118Z",
     "start_time": "2021-03-01T22:26:22.377352Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_params = {'min_samples_split' : [6,10,14],\n",
    "               'max_depth': [2,4, 5],\n",
    "               'max_leaf_nodes': [40,80,100]}\n",
    "\n",
    "grid_search = GridSearchCV(dt, grid_params, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:22.603678Z",
     "start_time": "2021-03-01T22:26:22.599244Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:22.609644Z",
     "start_time": "2021-03-01T22:26:22.604694Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T22:26:22.614026Z",
     "start_time": "2021-03-01T22:26:22.610956Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
